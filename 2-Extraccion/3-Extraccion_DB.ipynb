{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b1685f",
   "metadata": {},
   "source": [
    "# Extracción de datos desde DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae7817",
   "metadata": {},
   "source": [
    "## Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d862f18",
   "metadata": {},
   "source": [
    "### Conexión a bases de datos relacionales con ODBC y SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559129e6",
   "metadata": {},
   "source": [
    "#### Tipos de módulos de conexión\n",
    "Para desarrollar un proyecto en Python en el que se quiera implementar el uso \"Bases de Datos SQL\", se tienen distintos módulos que pueden ser útiles, por ejemplo \"PYODBC\" que es uno de ellos.\n",
    "\n",
    "**ODBC:**\n",
    "\n",
    "Open DataBase Connectivity (ODBC) es un estándar de acceso a las bases de datos desarrollado por SQL Access Group (SAG) en 1992. El objetivo de ODBC es hacer posible el acceder a cualquier dato desde cualquier aplicación, sin importar qué sistema de gestión de bases de datos (DBMS) almacené los datos.\n",
    "\n",
    "**PYODBC:**\n",
    "\n",
    "Pyodbc es un módulo de Python de código abierto que simplifica el acceso a las bases de datos \"ODBC\" desde Python, implementando el uso de la DB API 2.0 de una forma conveniente para Python. Pyodbc también es considerado como un controlador SQL para Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9e505",
   "metadata": {},
   "source": [
    "#### Configuracion de SQL Server\n",
    "\n",
    "So just open the access to your 127.0.0.1:1433 in the SQL server Configuration Manager.\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Start -> All Programs -> SQL Server Configuration Manager\n",
    "- SQL Server Network Configuration -> Protocols for MSSQLSERVER -> TCP/IP (Enable it)\n",
    "- TCP/IP -> Properties -> IP Addresses. Find 127.0.0.1 and change the \"Enabled\" to \"Yes\". You can do it for all the IPs if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b2ebb",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44260e",
   "metadata": {},
   "source": [
    "#### Librerías necesarias\n",
    "~~~bash\n",
    "conda install pymssql\n",
    "conda install pyodbc\n",
    "conda install sqlalchemy\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4500810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "# import pymssql # error en la py 3.13 05-25-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c222e",
   "metadata": {},
   "source": [
    "## DB SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d7e3d",
   "metadata": {},
   "source": [
    "### pymssql - error en py 3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c35a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymssql.connect(\n",
    "    server='localhost'\n",
    "    , database='etl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ee118",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute('SELECT top 5 * FROM information_schema.tables')\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cea8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT TOP 3 * FROM etl.dbo.dataset'\n",
    "cursor.execute(query)\n",
    "data = cursor.fetchall()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de8c43",
   "metadata": {},
   "source": [
    "### odbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drivers disponibles\n",
    "pyodbc.drivers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "server='localhost'\n",
    "database='etl'\n",
    "\n",
    "engine = create_engine(f'mssql+pyodbc://{server}/{database}?driver={driver}')\n",
    "\n",
    "try:\n",
    "    conn = engine.connect()\n",
    "    print(\"Connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo 1 - extrae todo\n",
    "df_tables = pd.read_sql_table('dataset', conn)\n",
    "df_tables.info()\n",
    "df_tables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo 2\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM etl.dbo.dataset\n",
    "WHERE Nombre_de_la_Campaña = 'CursosDeProgramacion'\n",
    "\"\"\"\n",
    "df = pd.read_sql(\n",
    "    sql=query,\n",
    "    con=conn\n",
    ")\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fda4af",
   "metadata": {},
   "source": [
    "### Polar - MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f35854",
   "metadata": {},
   "source": [
    "pl.read_database_uri:\n",
    "\n",
    "- Utiliza una cadena de conexión URI para especificar la conexión a la base de datos.\n",
    "- Es ideal cuando se trabaja con conexiones simples y se prefiere una sintaxis concisa.\n",
    "- Puede usar dos motores de conexión: ConnectorX (predeterminado) y ADBC.\n",
    "- ConnectorX es más versátil y admite una amplia gama de bases de datos, incluyendo PostgreSQL, MySQL, SQL Server y Redshift.\n",
    "- ADBC es más nuevo y tiene soporte a PostgreSQL, SQLite y Snowflake, pero puede ser más eficiente en algunos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'mysql://{user}:{password}@localhost:3306/{database}'.format(\n",
    "    user='root',\n",
    "    password='12345',\n",
    "    database='marketing'\n",
    ")\n",
    "query = 'SELECT * FROM marketing'\n",
    "df = pl.read_database_uri(query=query, uri=uri)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad4a26",
   "metadata": {},
   "source": [
    "pl.read_database:\n",
    "\n",
    "- Recibe un objeto de conexión creado con una biblioteca como SQLAlchemy.\n",
    "- Ofrece mayor flexibilidad para configurar la conexión y manejar transacciones.\n",
    "- Puede ser más lento que pl.read_database_uri si se usa SQLAlchemy o DBAPI2, ya que estos pueden cargar los datos fila por fila en Python antes de convertirlos al formato de Apache Arrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM etl.dbo.dataset\n",
    "WHERE Nombre_de_la_Campaña = 'CursosDeProgramacion'\n",
    "\"\"\"\n",
    "df = pl.read_database(\n",
    "    query=query,\n",
    "    connection = conn\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19080b",
   "metadata": {},
   "source": [
    "ConnectorX ofrece varios beneficios al leer datos de bases de datos con Polars:\n",
    "\n",
    "- **Lectura rápida**: ConnectorX está escrito en Rust, un lenguaje de programación conocido por su rendimiento. Esto permite una lectura eficiente de datos desde la base de datos.\n",
    "- **Zero-copy**: ConnectorX almacena los datos en formato Apache Arrow, lo que permite transferirlos a Polars sin necesidad de copiarlos. Esto reduce el tiempo de procesamiento y el uso de memoria.\n",
    "- **Paralelismo**: ConnectorX puede aprovechar el paralelismo para leer datos de la base de datos de forma más rápida, especialmente cuando se trabaja con grandes volúmenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65560a28",
   "metadata": {},
   "source": [
    "## DB NoSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5513473",
   "metadata": {},
   "source": [
    "La línea de código `pd.DataFrame(list(collection.find()))` está realizando varias operaciones para convertir los documentos de una colección de MongoDB en un DataFrame de Pandas. Aquí está la explicación detallada de cómo funciona:\n",
    "\n",
    "1. **`collection.find()`**:\n",
    "   - `collection` es un objeto que representa una colección en una base de datos MongoDB.\n",
    "   - El método `find()` se utiliza para realizar una consulta en la colección y recuperar todos los documentos. Si no se pasan parámetros a `find()`, se recuperan todos los documentos de la colección.\n",
    "   - El resultado de `find()` es un cursor, que es un iterador que permite recorrer los documentos recuperados uno por uno.\n",
    "\n",
    "2. **`list(collection.find())`**:\n",
    "   - La función `list()` toma el cursor devuelto por `find()` y lo convierte en una lista de documentos. Cada documento en la lista es un diccionario de Python que representa un documento de MongoDB.\n",
    "   - Esta conversión es necesaria porque el cursor no puede ser directamente pasado a `pd.DataFrame()`. La lista resultante contiene todos los documentos de la colección en forma de diccionarios.\n",
    "\n",
    "3. **`pd.DataFrame(list(collection.find()))`**:\n",
    "   - `pd.DataFrame()` es una función de la biblioteca Pandas que se utiliza para crear un DataFrame.\n",
    "   - Al pasar la lista de diccionarios a `pd.DataFrame()`, Pandas convierte cada diccionario en una fila del DataFrame. Las claves de los diccionarios se convierten en los nombres de las columnas del DataFrame.\n",
    "   - El resultado es un DataFrame de Pandas que contiene todos los documentos de la colección de MongoDB, con las columnas correspondientes a las claves de los diccionarios.\n",
    "\n",
    "En resumen, esta línea de código recupera todos los documentos de una colección de MongoDB, los convierte en una lista de diccionarios y luego crea un DataFrame de Pandas a partir de esa lista. Esto permite trabajar con los datos de MongoDB utilizando las poderosas herramientas de análisis y manipulación de datos que ofrece Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
